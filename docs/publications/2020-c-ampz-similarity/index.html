<!DOCTYPE html>
<html><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta name="description" content="Eric Medvet, Associate Professor of Computer Engineering at the University of Trieste, Italy" />
  <meta name="author" content="Eric Medvet" />
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous"/>
  <link rel="stylesheet" href="/scss/basic.css" />
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZW00T23DHQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag("js", new Date());
    gtag("config", "G-ZW00T23DHQ");
  </script>
  <title>On the Similarity between Hidden Layers of Pruned and Unpruned Convolutional Neural Networks</title>
</head>
<body>
    <div class="container">
      <div class="inner-container border rounded"><nav class="navbar navbar-expand-lg navbar-light bg-light">
  <a class="navbar-brand" href="https://ericmedvet.github.io/">
      <span class="initial">E</span><span>ric</span>
      <span class="initial">M</span><span>edvet</span></a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav">
      <a class="nav-link active" href="/publications/">Publications</a>
      <a class="nav-link " href="/teaching/">Teaching</a>
      <a class="nav-link " href="/contact/">Contact me</a>
    </div>
  </div>
</nav>
<div id="content">
<div class="container">
  <h1>On the Similarity between Hidden Layers of Pruned and Unpruned Convolutional Neural Networks</h1>

  <div class="publication-data">
    <h5>Type:</h5>
    <p><span class="badge-pub-type badge badge-pill badge-pub-type-secondary">Conf</span>
</p>

    <h5>Authors:</h5>
    <p>
        <span >Alessio Ansuini</span>, 
        <span class="this-author">Eric Medvet</span>, 
        <span >Felice Andrea Pellegrino</span>, 
        <span >Marco Zullich</span></p>

    <h5>In:</h5>
    <p>9th <strong>International Conference on Pattern Recognition Applications and Methods (ICPRAM)</strong>, held in Valletta (Malta)</p>

    <h5>Year:</h5>
    <p>2020</p>

    

    <h5>Links and material:</h5>
    <ul>
    <li><a href="https://scholar.google.com/scholar?q=on&#43;the&#43;similarity&#43;between&#43;hidden&#43;layers&#43;of&#43;pruned&#43;and&#43;unpruned&#43;convolutional&#43;neural&#43;networks">Google Scholar</a></li>
    <li><a href="http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0008960300520059">Publisher version</a></li>
    <li>DOI: <a href="https://doi.org/10.5220/0008960300520059">10.5220/0008960300520059</a></li>
    <li><a href="https://drive.google.com/uc?export=download&amp;id=1PmmmWzCt0528UuezZ24gBANKkEoNSiBN">Full text</a></li>
    <li><a href="https://drive.google.com/uc?export=download&amp;id=1029kgn5IJQxdCwqNft6tAFsI-5YclLpb">Slides</a></li>
    
    </ul>

  </div>

  <h2 id="abstract" class="wl">
  <span>Abstract</span>
  <a href="#abstract" aria-label="Anchor">#</a>
  <a href="#content">â†°</a>
</h2>
<p>During the last few decades, artificial neural networks (ANN) have achieved an enormous success in regression and classification tasks. The empirical success has not been matched with an equally strong theoretical understanding of such models, as some of their working principles (training dynamics, generalization properties and the structure of inner representations) still remain largely unknown. It is, for example, particularly difficult to reconcile the well known fact that ANNs achieve remarkable levels of generalization also in conditions of severe over-parametrization. In our work, we explore a recent network compression technique, called Iterative Magnitude Pruning (IMP), and apply it to convolutional neural networks (CNN). The pruned and unpruned models are compared layer-wise with Canonical Correlation Analysis (CCA). Our results show a high similarity between layers of pruned and unpruned CNNs in the first convolutional layers and in the fully-connected layer, while for the intermediate convolutional layers the similarity is significantly lower. This suggest that, although in intermediate layers representation in pruned and unpruned networks is markedly different, in the last part the fully-connected layers act as pivots, producing not only similar performances but also similar representations of the data, despite the large difference in the number of parameters involved.</p>

</div>

        </div>
      </div>
<div id="footer">
  <div class="text-center">
    Copyright by Eric Medvet
  </div>
</div>

</div>
  </body>
</html>
