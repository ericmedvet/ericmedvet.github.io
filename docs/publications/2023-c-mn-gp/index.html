<!DOCTYPE html>
<html><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <meta name="description" content="Eric Medvet, Associate Professor of Computer Engineering at the University of Trieste, Italy" />
  <meta name="author" content="Eric Medvet" />
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous"/>
  <link rel="stylesheet" href="/scss/basic.css" />
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZW00T23DHQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag("js", new Date());
    gtag("config", "G-ZW00T23DHQ");
  </script>
  <title>GP for Continuous Control: Teacher or Learner? The Case of Simulated Modular Soft Robots</title>
</head>
<body>
    <div class="container">
      <div class="inner-container border rounded"><nav class="navbar navbar-expand-lg navbar-light bg-light">
  <a class="navbar-brand" href="https://ericmedvet.github.io/">
      <span class="initial">E</span><span>ric</span>
      <span class="initial">M</span><span>edvet</span></a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavAltMarkup" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="collapse navbar-collapse" id="navbarNavAltMarkup">
    <div class="navbar-nav">
      <a class="nav-link active" href="/publications/">Publications</a>
      <a class="nav-link " href="/teaching/">Teaching</a>
      <a class="nav-link " href="/contact/">Contact me</a>
    </div>
  </div>
</nav>
<div id="content">
<div class="container">
  <h1>GP for Continuous Control: Teacher or Learner? The Case of Simulated Modular Soft Robots</h1>

  <div class="publication-data">
    <h5>Type:</h5>
    <p><span class="badge-pub-type badge badge-pill badge-pub-type-secondary">Conf</span>
</p>

    <h5>Authors:</h5>
    <p>
        <span class="this-author">Eric Medvet</span>, 
        <span >Giorgia Nadizar</span></p>

    <h5>In:</h5>
    <p>XX <strong>Genetic Programming Theory &amp; Practice (GPTP)</strong>, held in East Lansing (USA)</p>

    <h5>Year:</h5>
    <p>2023</p>

    
      <h5>Notes:</h5>
      <p>To appear</p>
    

    <h5>Links and material:</h5>
    <ul>
    <li><a href="https://scholar.google.com/scholar?q=gp&#43;for&#43;continuous&#43;control&#43;&#43;teacher&#43;or&#43;learner&#43;&#43;the&#43;case&#43;of&#43;simulated&#43;modular&#43;soft&#43;robots">Google Scholar</a></li>
    
    
    <li><a href="https://drive.google.com/file/d/1sxsxIg2DoE05JqSdzqS6alubSQ_XST0p/view">Full text</a></li>
    <li><a href="https://medvet.inginf.units.it/slides/2023-gptp-gp-continuous-control-imitation/#1">Slides</a></li>
    
    </ul>

  </div>

  <h2 id="abstract" class="wl">
  <span>Abstract</span>
  <a href="#abstract" aria-label="Anchor">#</a>
  <a href="#content">↰</a>
</h2>

<p>We consider the problem of optimizing a controller for agents whose observation and action spaces are continuous, i.e., where the controller is a multivariate real function f: R^n → R^m. We use genetic programming (GP) for solving this optimization problem. Namely, we employ a multi-tree-based GP variant, where a candidate solution is an array of $m$ trees, each encoding a univariate function of the agent observation. We compare this form of optimization against the more common one where the controller is a multi-layer perceptron, with a predefined topology, whose weights are optimized through (neuro)evolution (NE). Moreover, we consider an evolutionary algorithm, GraphEA, that directly evolves graphs, each having $n$ input nodes and $m$ output nodes. We apply these three approaches to the case of simulated modular soft robots, where a robot is an aggregation of identical soft modules, each employing a controller that processes the local observation and produces the local action. We find that, in our scenario, multi-tree-based GP is competitive with NE and tends to produce different behaviors. We then experimentally investigate the possibility of optimizing a controller using another, pre-optimized one, as teacher, i.e., we realize a form of offline imitation learning. We consider all the teacher-learner pairs resulting from the three evolutionary algorithms and find that NE is a better learner than GP and GraphEA. However, controllers obtained through offline imitation learning are far less effective than those obtained through direct evolution. We hypothesize that this gap in effectiveness may be explained by the possibility, given by direct evolution, of exploring during the simulations a larger portion of the observation-action space.</p>
<h2 id="code-data-and-videos" class="wl">
  <span>Code, data, and videos</span>
  <a href="#code-data-and-videos" aria-label="Anchor">#</a>
  <a href="#content">↰</a>
</h2>

<p><a href="https://github.com/ericmedvet/2023-GPForContinuousControlAndLearning">Github repository</a></p>

</div>

        </div>
      </div>
<div id="footer">
  <div class="text-center">
    Copyright by Eric Medvet
  </div>
</div>

</div>
  </body>
</html>
