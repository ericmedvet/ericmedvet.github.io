{
  "title": "Searching for a Diversity of Interpretable Graph Control Policies",
  "pub_year": 2024,
  "pub_accept_year": 2024,
  "pub_type": "Conference",
  "pub_venue_name": "ACM Genetic and Evolutionary Computation Conference",
  "pub_venue_acronym": "GECCO",
  "pub_location_city": "Melbourne",
  "pub_location_country": "Australia",
  "pub_authors": "Nadizar, Giorgia; Medvet, Eric; Wilson, Dennis G.",
  "pub_doi": "10.1145/3638529.3653987",
  "pub_notes": "To appear",
  "pub_fulltext_url": "https://drive.google.com/file/d/1rXiOaZlAFRnwb4ZayXL2nkm4C4pTNHFd/view",
  "pub_slides_url": "https://drive.google.com/file/d/1YOvTFPQlOEIQaQ8eLjM8mNcgpWzVBg4D/view",
  "pub_important": false
}

## Abstract
Graph-based Genetic Programming (GGP) can create interpretable control policies in graph form, but faces challenges such as local optima and solution fragility, which undermine its efficacy. Quality-Diversity (QD) has been effective in addressing similar issues, traditionally in Artificial Neural Network (ANN) optimization. In this paper, we introduce a general Graph Quality-Diversity (G-QD) framework to enhance the performance of GGP with QD optimization, obtaining a variety of interpretable, effective, and resilient policies. Using Cartesian Genetic Programming (CGP) as the GGP technique and MAP-Elites (ME) as the QD algorithm, we leverage a combination of behavior and graph structural descriptors. Experimenting on two navigation and two locomotion continuous control tasks, our framework yields an array of effective yet behaviorally and structurally diverse policies, surpassing the performance of a standard Genetic Algorithm (GA). The resulting solution set also increases interpretability, allowing for insight into the control tasks. Additionally, our experiments demonstrate the robustness of the to faults such as sensor damage.
