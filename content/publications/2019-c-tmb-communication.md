{
  "title": "Communication-based Cooperative Tasks: how the Language Expressiveness affects Reinforcement Learning",
  "pub_year": 2019,
  "pub_accept_year": 2019,
  "pub_type": "Conference",
  "pub_venue_name": "ACM/SIGAPP Symposium on Applied Computing",
  "pub_venue_number": "34th",
  "pub_venue_acronym": "SAC",
  "pub_location_city": "Limassol",
  "pub_location_country": "Cyprus",
  "pub_authors": "Talamini, Jacopo; Medvet, Eric; Bartoli, Alberto",
  "pub_doi": "10.1145/3297280.3297368",
  "pub_publisher_url": "https://dl.acm.org/citation.cfm?id=3297368",
  "pub_fulltext_url": "https://drive.google.com/file/d/1eOc4kyEIqcw8c2Zjoe0kI7ae3lgcBr1P/view",
  "pub_slides_url": "https://drive.google.com/file/d/1tPGJoyGuGhongnxz2Q6DWvHxbQ_ydO5V/view",
  "pub_important": false
}

## Abstract
We consider a cooperative multi-agent system in which cooperation may be enforced by communication between agents but in which agents must learn to communicate. The system consists of a game in which agents may move in a 2D world and are given the task of reaching specified targets. Each agent knows the target of another agent but not its own, thus the only way to solve the task is for the agents to guide one another using communication and, in particular, by learning how to communicate. We cast this game in terms of a partially observed Markov game and show that agents may learn policies for moving and communicating in the form of a neural network by means of reinforcement learning. We investigate in depth the impact on the learning quality of the expressiveness of the language, which is a function of vocabulary size, number of agents and number of targets.
